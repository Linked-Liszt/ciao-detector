{
 "cells": [
  {
   "source": [
    "## Imports and defining helper functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, loader, specific_class=None) -> float:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            if specific_class is None:\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "            else:\n",
    "                for predict, label in zip(predicted, labels):\n",
    "                    if label == specific_class:\n",
    "                        total += 1\n",
    "                        if label == predict:\n",
    "                            correct += 1\n",
    "    model.trian()\n",
    "    return correct / total"
   ]
  },
  {
   "source": [
    "## Defining the image preprocessing before they enter the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(80),\n",
    "    transforms.CenterCrop(80),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "source": [
    "## Importing the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'demo_dataset'\n",
    "batch_size = 8\n",
    "num_worksers = 2\n",
    "\n",
    "train_set = datasets.ImageFolder(os.path.join('datasets', dataset, 'training'), transform = transformations)\n",
    "test_set = datasets.ImageFolder(os.path.join('datasets', dataset, 'test'), transform = transformations)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "source": [
    "## Define the model and optimizer\n",
    "\n",
    "Can hot-swap models:  https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "Or the optimzers here: https://pytorch.org/docs/stable/optim.html\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "net = models.mobilenet_v2(pretrained=False, progress=True).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Initialize results tracking"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "\n",
    "results_fp = os.path.join('results', f'{dataset}.csv')\n",
    "if os.path.exists(results_fp):\n",
    "    input('Warning. Results File Exists [return to continue]')\n",
    "\n",
    "with open(results_fp, 'w') as results_f:\n",
    "    results_f.write('Batches, Training Accuracy, Test Accuracy\\n')"
   ]
  },
  {
   "source": [
    "## Set Training Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "minibatch_save_interval = 2000"
   ]
  },
  {
   "source": [
    "##  Train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_acc = 0.0\n",
    "loss = 0.0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    net.train()\n",
    "    running_accuracy = []\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        running_accuracy.append((labels == predicted).sum().item())\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % minibatch_save_interval == (minibatch_save_interval - 1):\n",
    "            with torch.no_grad():\n",
    "                test_accuracy = get_accuracy(net, test_loader)\n",
    "\n",
    "            with open(results_fp, 'a') as results_f:\n",
    "                results_f.write(f'{i * (epoch + 1)},{np.mean(running_accuracy) / batch_size},{test_accuracy}\\n')\n",
    "\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / minibatch_save_interval))\n",
    "            running_loss = 0.0\n",
    "            print(f'Train: {np.mean(running_accuracy) / batch_size} Test: {test_accuracy}')\n",
    "\n",
    "            if test_accuracy > best_test_acc:\n",
    "                torch.save(net.state_dict(), os.path.join('results', f'{dataset}_m.p'))\n",
    "                best_test_acc = test_accuracy\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "source": [
    "## See Final Accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_accuracy(net, test_loader)"
   ]
  },
  {
   "source": [
    "## See Confusion Matrix on Test Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = torch.zeros(len(test_set.classes), len(test_set.classes))\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, (inputs, classes) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "    model.train()\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "source": [
    "## Visualize Confusion Matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(confusion_matrix.numpy(), index = test_set.classes,\n",
    "                  columns = test_set.classes)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd046e2feffbcfc711fb3770a049d1d4e0d197b4dd9ad6655ca17ff1201a7baa020",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}